{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# ===============================\n",
    "# 1. Imports & device\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ===============================\n",
    "# 2. Transformations\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(15),  # rotation ±15°\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # translation & zoom\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # légère variation\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalisation sera ajoutée après calcul de mean/std\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalisation sera ajoutée après calcul de mean/std\n",
    "])\n",
    "\n",
    "# ===============================\n",
    "# 3. Dataset & split\n",
    "data_dir = \"/home/chaouchix/data/chest_xray/train\"\n",
    "full_dataset = datasets.ImageFolder(data_dir, transform=train_transform)\n",
    "\n",
    "# Calcul de la vraie moyenne et std\n",
    "loader = DataLoader(full_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0\n",
    "for data, _ in loader:\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1), -1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "print(\"Computed mean:\", mean)\n",
    "print(\"Computed std:\", std)\n",
    "\n",
    "# Ajouter normalisation aux transformations\n",
    "train_transform.transforms.append(transforms.Normalize(mean.tolist(), std.tolist()))\n",
    "val_test_transform.transforms.append(transforms.Normalize(mean.tolist(), std.tolist()))\n",
    "\n",
    "# Split train/val\n",
    "val_size = int(0.1 * len(full_dataset))\n",
    "train_size = len(full_dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "val_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "# Test dataset\n",
    "test_dir = \"/home/chaouchix/data/chest_xray/test\"\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transform)\n",
    "\n",
    "# ===============================\n",
    "# 4. WeightedRandomSampler pour balance des classes\n",
    "targets = [y for _, y in train_dataset]\n",
    "class_sample_count = np.bincount(targets)\n",
    "weights = 1. / class_sample_count\n",
    "samples_weights = np.array([weights[t] for t in targets])\n",
    "samples_weights = torch.from_numpy(samples_weights).double()\n",
    "sampler = WeightedRandomSampler(samples_weights, len(samples_weights))\n",
    "\n",
    "# ===============================\n",
    "# 5. DataLoaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=0),\n",
    "    'val': DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0),\n",
    "    'test': DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0),\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# 6. Info\n",
    "class_names = full_dataset.classes\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset), 'test': len(test_dataset)}\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Dataset sizes:\", dataset_sizes)\n",
    "\n",
    "# ===============================\n",
    "# 7. Check a batch\n",
    "x, y = next(iter(dataloaders['train']))\n",
    "print(\"Batch images shape:\", x.shape)\n",
    "print(\"Batch labels shape:\", y.shape)\n",
    "print(\"Sample labels:\", y[:10])\n"
   ],
   "id": "9e6d7dbe3d97d533",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PneumoCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN pour classification Pneumonia vs Normal\n",
    "    - 5 blocs conv\n",
    "    - BatchNorm + ReLU\n",
    "    - Dropout pour régularisation\n",
    "    - GAP pour réduire les paramètres fully-connected\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        def conv_block(in_c, out_c, p_dropout=0.3):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Dropout2d(p_dropout)\n",
    "            )\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            conv_block(1, 32, p_dropout=0.2),    # 224 -> 112\n",
    "            conv_block(32, 64, p_dropout=0.3),   # 112 -> 56\n",
    "            conv_block(64, 128, p_dropout=0.3),  # 56 -> 28\n",
    "            conv_block(128, 256, p_dropout=0.4), # 28 -> 14\n",
    "            conv_block(256, 512, p_dropout=0.4)  # 14 -> 7\n",
    "        )\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Exemple d'instanciation CPU\n",
    "device = torch.device(\"cpu\")\n",
    "model = PneumoCNN().to(device)\n",
    "print(f\"Params: {sum(p.numel() for p in model.parameters())/1e6:.2f} M\")\n"
   ],
   "id": "f31b5fd8696a7f3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Récupérer les labels du train_dataset\n",
    "train_targets = [y for _, y in train_dataset]\n",
    "counts = Counter(train_targets)\n",
    "\n",
    "# Pondérations inverses\n",
    "total = sum(counts.values())\n",
    "class_weights = torch.tensor([total/counts[i] for i in range(len(class_names))], dtype=torch.float)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n"
   ],
   "id": "d3de7b263e1d1795"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_epochs = 5  # tu peux ajuster\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(dataloaders['train']):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "        # Affichage toutes les 10 batches\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {i}/{len(dataloaders['train'])} - Loss: {loss.item():.4f}\", flush=True)\n",
    "\n",
    "    epoch_loss = running_loss / dataset_sizes['train']\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
    "\n",
    "    # Évaluation sur le set de validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels)\n",
    "    val_loss /= dataset_sizes['val']\n",
    "    val_acc = val_corrects.double() / dataset_sizes['val']\n",
    "\n",
    "    print(f\"*** Epoch {epoch+1} complete - \"\n",
    "          f\"Train Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f} ***\")\n"
   ],
   "id": "7711ad86b1a273eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "test_correct, test_total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += torch.sum(preds == labels)\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "print(\"Final Test Accuracy:\", test_correct.double() / test_total)\n"
   ],
   "id": "9ff596cf41fec98f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
